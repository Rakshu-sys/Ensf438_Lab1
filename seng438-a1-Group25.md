>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group: Group Number      |
|-----------------|
| Mohit Kaila                |   
| Rakshita Suri              |   
| Okibe Abang               |   
| Student 4 name                |   


**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction	1](#_Toc439194677)

[2 High-level description of the exploratory testing plan	1](#_Toc439194678)

[3 Comparison of exploratory and manual functional testing	1](#_Toc439194679)

[4 Notes and discussion of the peer reviews of defect reports	1](#_Toc439194680)

[5 How the pair testing was managed and team work/effort was
divided	1](#_Toc439194681)

[6 Difficulties encountered, challenges overcome, and lessons
learned	1](#_Toc439194682)

[7 Comments/feedback on the lab and lab document itself	1](#_Toc439194683)

# Introduction

This lab focused on different software testing methodologies, specifically exploratory and 
manual functional testing. Before this lab, we understood exploratory testing as an unscripted 
testing approach where testers freely navigate the application to discover defects. we also knew 
manual functional testing as a structured testing approach, where predefined test cases are 
executed to validate system functionality against requirements.

# High-level description of the exploratory testing plan

Exploratory testing was used to evaluate the ATM simulation system without following 
predefined test cases. This method allowed testers to freely interact with the system, observing 
its behavior and identifying possible defects. Unlike manual functional testing, which follows a 
set script, exploratory testing is flexible and adapts as new issues are discovered.
To keep the testing process organized, the system was broken down into key functions:

• System startup and shutdown  
• Card validation and PIN entry  
• Withdrawals, deposits, and transfers  
• Balance inquiries  
• Transaction failures and errors  
• Receipt generation  
• Operator functions and logs  

Each function was tested individually to ensure comprehensive coverage. Critical areas, such as 
security-related functions (PIN entry and account validation), were tested more thoroughly. The 
team members tested different parts of the system independently and then combined their 
findings to ensure no defects were missed. Peer reviews helped refine defect reports, making sure 
all issues were well-documented and reproducible.

# Comparison of exploratory and manual functional testing
| **Aspect**          | **Exploratory Testing**                     | **Manual Functional Testing**               |
|---------------------|---------------------------------|----------------------------------|
| **Approach**       | Unscripted, intuitive          | Scripted, follows predefined test cases |
| **Flexibility**    | High                           | Low                                  |
| **Coverage**       | Unpredictable, depends on tester's skills | Systematic, covers specified requirements |
| **Efficiency**     | Fast for uncovering unknown issues | Ensures thorough validation of expected functionalities |
| **Documentation**  | Minimal, relies on defect tracking reports | Detailed, test cases and reports are required |


# Notes and discussion of the peer reviews of defect reports

Peer review of defect reports was essential in improving report clarity and accuracy. In our experience, we found that peer reports helped consolidate certain issues, provided a second pair of eyes to spot simple mistakes and enhanced our collaborative capabilities.

Some common feedback included:  

• Improving defect descriptions for better reproducibility  
• Providing clearer steps to reproduce issues  
• Ensuring defect severity levels were appropriately assigned  
• Avoiding duplicate bug reports by checking the tracking system first  

# How the pair testing was managed and team work/effort was divided 

Pairs: 

Mohit & Rakshita 
Okibe & Shalin 

Our team had 4 members that worked together by splitting into pairs to manage testing effectively:

- In each pair, one person ran the tests and found any issues, while the other recorded the problems and double-checked everything.
- We switched roles often so that everyone got a chance to do both testing and documentation.
- For exploratory testing, we worked in pairs by taking 15-minute turns—one person tested while the other reviewed the work.
- During manual functional testing (MFT), we divided 40 test cases between the two pairs, with each person handling 10 cases.
- We used the same approach for regression testing to make sure all areas were covered and tested well.
- This teamwork helped us find important issues early, understand the system better, and be well-prepared for the demo.

# Difficulties encountered, challenges overcome, and lessons learned

Challenges faced during the lab included:

• Understanding the SUT functionality: Overcome by reviewing documentation and experimenting with features

• Identifying and categorizing defects: Improved through collaboration and peer feedback

• Efficiently using the defect tracking system: Learned by exploring its functionalities and refining report entries

Lessons learned:  

• Exploratory testing requires critical thinking and adaptability  

• Clear defect documentation improves issue resolution efficiency

• Collaboration enhances testing effectiveness and knowledge sharing  

# Comments/feedback on the lab and lab document itself

The lab manual was well-organized and gave us hands-on experience with software testing. It was self-explanatory for most of the parts. It helped us learn about different types of testing, like exploratory, manual functional, and regression testing. It also improved our testing and pair testing skills. The instructions were clear, and the different sections made the key concepts easier to understand. However, a few things could be improved, like providing more examples of good defect reports and explaining the severity levels more clearly. A quick tutorial on the defect tracking system before testing would have made things run smoother. Overall, the lab was a good learning experience. 
